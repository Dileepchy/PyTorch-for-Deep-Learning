{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v2p9GJ9Mjs6b"
      },
      "source": [
        "#**Introduction to PyTorch**\n",
        "In this reading assignment, you'll be introduced to a different method to build a Pytorch model. We will be using PyTorch throughout the course as well.\n",
        "\n",
        "##Prerequisites:\n",
        "\n",
        "\n",
        "1.   Basics of Python Programming\n",
        "2.   Basics of Object Oriented Programming\n",
        "\n",
        "##Learning Objectives:\n",
        "\n",
        "\n",
        "1.   Learn to implement Pytorch model\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b7wumR6ETWKF"
      },
      "source": [
        "# <h1><b>Methods to build a Pytorch model</b></h1>\n",
        "\n",
        "\n",
        "\n",
        "*   Sequential\n",
        "*   Functional API\n",
        "*   Model Subclassing\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_OMoQwDrTW_k"
      },
      "source": [
        "##<h2><b>Sequential Model</b></h2>\n",
        "\n",
        "Sequential model is a linear stack of layers but you are limited to one input and output. Sequential model is best choice when you want simple stack by stack layer model. The first layer of sequential model need to know input shape of dataset.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PtYgAhQqUOtl"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch import nn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tkzI23AMVFkp"
      },
      "outputs": [],
      "source": [
        "model = nn.Sequential(\n",
        "  nn.Linear(4, 5),\n",
        "  nn.ReLU(),\n",
        "  nn.Linear(5, 8),\n",
        "  nn.ReLU(),\n",
        "  nn.Linear(8, 3),\n",
        "  nn.Softmax(dim=-1),\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zitne3dEVg1g",
        "outputId": "3936e5a8-3f8a-4b98-b1b8-d341a8ff3e6d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Sequential(\n",
              "  (0): Linear(in_features=4, out_features=5, bias=True)\n",
              "  (1): ReLU()\n",
              "  (2): Linear(in_features=5, out_features=8, bias=True)\n",
              "  (3): ReLU()\n",
              "  (4): Linear(in_features=8, out_features=3, bias=True)\n",
              "  (5): Softmax(dim=-1)\n",
              ")"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Model Architecture\n",
        "model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fUPZJpHr08aD",
        "outputId": "77d19577-618d-4f2b-a7ba-81a04ffa6469"
      },
      "outputs": [],
      "source": [
        "# forward pass with random input\n",
        "model(torch.randn(5, 4))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F7QHgYbUfwmU"
      },
      "source": [
        "## <h2><b>Manual building parameters and operating using torch.nn.functional API</b></h2>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VZ06ScivgJpJ"
      },
      "source": [
        "The `torch.nn.functional` api deliver more low level and flexible way to build model than sequential model. It can handle complex model, multiple input or output models, custom operations as well as models that share layers."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7yP1j1zsgJ4J"
      },
      "source": [
        "\n",
        "\n",
        "First we need to define an input, parameters of each layers of ANN(random for this tutorial). Then `torch.nn.functional` API is used to manipulate the inputs  with the custom defined model parameters.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fFmCFiohf5Eh"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn.functional as F"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WqJwZMalB7hA",
        "outputId": "0689ba06-adfc-4fea-b555-161cca94d0d5"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0., 0., 1., 0., 0.]], grad_fn=<SoftmaxBackward0>)"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# generate random input, 4 examples with 28*28 features each are created\n",
        "inputs = torch.randn(4, 28*28)\n",
        "\n",
        "# generate parameters(Weights and Biases) for each layers,\n",
        "# gradient calculation for this parameters need to be enabled for back propagation\n",
        "# define the weights, shape should be (out_dim, in_dim)\n",
        "W1 = torch.randn((64, 28*28), requires_grad=True)\n",
        "W2 = torch.randn((64, 64), requires_grad=True)\n",
        "W3 = torch.randn((10, 64), requires_grad=True)\n",
        "\n",
        "# define the bias terms, shape should be (out_dim)\n",
        "B1 = torch.randn((64), requires_grad=True)\n",
        "B2 = torch.randn((64), requires_grad=True)\n",
        "B3 = torch.randn((10), requires_grad=True)\n",
        "\n",
        "# Layer 1 operation\n",
        "h1 = F.relu(F.linear(inputs, W1, B1))\n",
        "# Layer 2 operation\n",
        "h2 = F.relu(F.linear(h1, W2, B2))\n",
        "# Output Layer operation\n",
        "output = F.softmax(F.linear(h2, W3, B3), dim=-1)\n",
        "output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZvdQz2j_Covj",
        "outputId": "51680ff7-d365-46e4-ca2f-54b95627b81a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([4, 10])"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "Basicoutput.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EJFn9-cH8a04"
      },
      "source": [
        "## <h2><b>Model Subclassing</b></h2>\n",
        "\n",
        "The last method to build the PyTorch model is called model subclassing. Model subclassing is completely customizable and allows us to build our own custom forward-pass of the model. In PyTorch the `nn.Module` class is the root class used to define a model architecture. In model subclassing implementation, MyModel inherits from the `nn.Module` class. The structure of model subclassing is that we create layers in the initializer __init__() and define the forward pass in the forward() method.\n",
        "\n",
        "<center>\n",
        "<figure>\n",
        "<img src=\"https://doc.google.com/a/fusemachines.com/uc?export=download&id=1_4Xbdu_folAQh4tUzGl1JLwiozwW0eHm\" alt=\"gradient_update\">\n",
        "<figcaption align=\"center\">Model Subclassing</figcaption>\n",
        "</figure>\n",
        "</center>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HqLs0a5GyVJr"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch import nn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YAPYAyRs8HlF"
      },
      "outputs": [],
      "source": [
        "# MyModel inherits from the nn.Module class\n",
        "class MyModel(nn.Module):\n",
        "  #Initialize the layers\n",
        "  def __init__(self, in_features, **kwargs):\n",
        "    super(MyModel,self).__init__(**kwargs)\n",
        "    self.dense1 = nn.Linear(in_features, 16)\n",
        "    self.act1 = nn.ReLU()\n",
        "    self.dense2 = nn.Linear(16, 32)\n",
        "    self.act2 = nn.ReLU()\n",
        "    self.dense3 = nn.Linear(32, 5)\n",
        "    self.act3 = nn.Softmax(dim=-1)\n",
        "\n",
        "  # Forward pass\n",
        "  def forward(self,inputs):\n",
        "    x = self.act1(self.dense1(inputs))\n",
        "    x = self.act2(self.dense2(x))\n",
        "    x = self.act3(self.dense3(x))\n",
        "    return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SSN3GDKURAPz",
        "outputId": "d4b6b81d-1b4a-4f03-9183-6539f5b6cdf1"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "MyModel(\n",
              "  (dense1): Linear(in_features=4, out_features=16, bias=True)\n",
              "  (act1): ReLU()\n",
              "  (dense2): Linear(in_features=16, out_features=32, bias=True)\n",
              "  (act2): ReLU()\n",
              "  (dense3): Linear(in_features=32, out_features=5, bias=True)\n",
              "  (act3): Softmax(dim=-1)\n",
              ")"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Model initialization and architecture\n",
        "model = MyModel(4)\n",
        "model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nmr5Xb-MREjx",
        "outputId": "39f9edb2-9e7d-47b6-9b15-499e0f9585e5"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[0.1960, 0.1673, 0.2338, 0.1879, 0.2150],\n",
              "        [0.2018, 0.1580, 0.2144, 0.1979, 0.2279],\n",
              "        [0.1986, 0.1812, 0.2193, 0.2048, 0.1960],\n",
              "        [0.2236, 0.1663, 0.2267, 0.1839, 0.1995],\n",
              "        [0.2124, 0.1840, 0.2268, 0.1893, 0.1875],\n",
              "        [0.1929, 0.1562, 0.2399, 0.1763, 0.2346],\n",
              "        [0.1839, 0.1659, 0.2421, 0.1830, 0.2250],\n",
              "        [0.1875, 0.1620, 0.2132, 0.2181, 0.2192]], grad_fn=<SoftmaxBackward0>)"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Forward pass with random input\n",
        "model(torch.randn(8, 4))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0DK-L3iQKBFc"
      },
      "source": [
        "# **Multi inputs and outputs**\n",
        "\n",
        "Scenario\n",
        "\n",
        "\n",
        "*   One input and two output: if we only have image data and we need to find out that the image is flower or not. if it is a flower what kind of flower it is?\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JngYXme_J0N9"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "import torch.nn.functional as F"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "012VjoxMd9Ei",
        "outputId": "8a98da34-d002-42cc-f7ef-a6d84f51b3da"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "SingleInpMultiOutModel(\n",
              "  (dense): Linear(in_features=64, out_features=128, bias=True)\n",
              "  (out1): Linear(in_features=128, out_features=3, bias=True)\n",
              "  (out2): Linear(in_features=128, out_features=1, bias=True)\n",
              ")"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "class SingleInpMultiOutModel(nn.Module):\n",
        "    def __init__(self, in_features, **kwargs):\n",
        "        super(SingleInpMultiOutModel, self).__init__(**kwargs)\n",
        "        # Common Layer\n",
        "        self.dense = nn.Linear(in_features, 128)\n",
        "\n",
        "        # Output layers\n",
        "        self.out1 = nn.Linear(128, 3)\n",
        "        self.out2 = nn.Linear(128, 1)\n",
        "\n",
        "    def forward(self, inputs):\n",
        "        comm = F.relu(self.dense(inputs))\n",
        "        out1 = F.softmax(self.out1(comm), dim=-1)\n",
        "        out2 = torch.sigmoid(self.out2(comm))\n",
        "        return out1, out2\n",
        "\n",
        "# Define Model\n",
        "model = SingleInpMultiOutModel(64)\n",
        "model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xwXYLkZGh2vS",
        "outputId": "f4f731a2-900a-434b-8d3d-4c192370c36e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(tensor([[0.2854, 0.3190, 0.3956],\n",
              "         [0.3456, 0.2737, 0.3807],\n",
              "         [0.3145, 0.2875, 0.3980],\n",
              "         [0.2339, 0.4925, 0.2736]], grad_fn=<SoftmaxBackward0>),\n",
              " tensor([[0.4719],\n",
              "         [0.5441],\n",
              "         [0.5017],\n",
              "         [0.4375]], grad_fn=<SigmoidBackward0>))"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Forward pass with random input\n",
        "model(torch.randn(4, 64))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uRociGFljcy8"
      },
      "source": [
        "*   Two input and one output: if we only have image data and structured data and we need to find out that what kind of flower is it?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Li8v1CBhi-7P",
        "outputId": "bbf06a7a-2c27-4997-bd4d-a9156ce5fb7b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "MultiInpSingleOutModel(\n",
              "  (dense1): Linear(in_features=784, out_features=10, bias=True)\n",
              "  (dense2): Linear(in_features=4, out_features=64, bias=True)\n",
              "  (output): Linear(in_features=74, out_features=3, bias=True)\n",
              ")"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "class MultiInpSingleOutModel(nn.Module):\n",
        "    def __init__(self, in_features1, in_features2, **kwargs):\n",
        "        super(MultiInpSingleOutModel, self).__init__(**kwargs)\n",
        "        # separate input path Layer\n",
        "        self.dense1 = nn.Linear(in_features1, 10)\n",
        "        self.dense2 = nn.Linear(in_features2, 64)\n",
        "\n",
        "        # Output layers\n",
        "        self.output = nn.Linear(64+10, 3) # after concatenation features to this layer will have shape of(batch_size, 64+10)\n",
        "\n",
        "    def forward(self, input1, input2):\n",
        "        x1 = F.relu(self.dense1(input1))\n",
        "        x2 = F.relu(self.dense2(input2))\n",
        "        x = torch.concat([x1, x2], dim=-1)  # concatenate using last dimension\n",
        "        out = F.softmax(self.output(x), dim=-1)\n",
        "        return out\n",
        "\n",
        "# Define Model\n",
        "model = MultiInpSingleOutModel(784, 4)\n",
        "model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rpGREQU8lb32",
        "outputId": "7fefdba0-6060-47a0-8f18-bec0fd5f80c0"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[0.2752, 0.3207, 0.4041],\n",
              "        [0.2402, 0.3278, 0.4320],\n",
              "        [0.2811, 0.2587, 0.4602],\n",
              "        [0.3392, 0.3496, 0.3112],\n",
              "        [0.2647, 0.2636, 0.4718]], grad_fn=<SoftmaxBackward0>)"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Forward pass with random inputs\n",
        "model(torch.randn(5, 784),\n",
        "      torch.randn(5, 4))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "84yCam-il67N"
      },
      "source": [
        "\n",
        " **Two input and Two output**: If we only have image data and structured data and we need to find out the image is flower or not. if it is a flower what kind of flower it is?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "USh-y0aOlukf",
        "outputId": "8ddd66e4-7d83-45ec-f0f5-a1d1013dcb13"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "MultiInpMultiOutModel(\n",
              "  (dense1): Linear(in_features=784, out_features=10, bias=True)\n",
              "  (dense2): Linear(in_features=4, out_features=64, bias=True)\n",
              "  (output1): Linear(in_features=74, out_features=3, bias=True)\n",
              "  (output2): Linear(in_features=74, out_features=1, bias=True)\n",
              ")"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "class MultiInpMultiOutModel(nn.Module):\n",
        "    def __init__(self, in_features1, in_features2, **kwargs):\n",
        "        super(MultiInpMultiOutModel, self).__init__(**kwargs)\n",
        "        # separate input path Layer\n",
        "        self.dense1 = nn.Linear(in_features1, 10)\n",
        "        self.dense2 = nn.Linear(in_features2, 64)\n",
        "\n",
        "        # Output layers\n",
        "        self.output1 = nn.Linear(64+10, 3) # after concatenation features to this layer will have shape of(batch_size, 64+10)\n",
        "        self.output2 = nn.Linear(64+10, 1)\n",
        "\n",
        "    def forward(self, input1, input2):\n",
        "        x1 = F.relu(self.dense1(input1))\n",
        "        x2 = F.relu(self.dense2(input2))\n",
        "        x = torch.concat([x1, x2], dim=-1)  # concatenate using last dimension\n",
        "        out1 = F.softmax(self.output1(x), dim=-1)\n",
        "        out2 = torch.sigmoid(self.output2(x))\n",
        "        return out1, out2\n",
        "\n",
        "# Define Model\n",
        "model = MultiInpMultiOutModel(784, 4)\n",
        "model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uXS0xmD8mUF4",
        "outputId": "d8cf1bab-2e7c-4358-9aad-95ab19af4c96"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(tensor([[0.2486, 0.4236, 0.3278],\n",
              "         [0.2756, 0.3695, 0.3549],\n",
              "         [0.2355, 0.3857, 0.3788],\n",
              "         [0.2473, 0.3889, 0.3638],\n",
              "         [0.1644, 0.3778, 0.4577]], grad_fn=<SoftmaxBackward0>),\n",
              " tensor([[0.5052],\n",
              "         [0.4569],\n",
              "         [0.4962],\n",
              "         [0.4677],\n",
              "         [0.4761]], grad_fn=<SigmoidBackward0>))"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Forward pass with random inputs\n",
        "model(torch.randn(5, 784),\n",
        "      torch.randn(5, 4))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fsPjLQFWmslX"
      },
      "source": [
        "<h2><b>Shared layer</b></h2>\n",
        "\n",
        "One of the benefit to use model subclassing is it allows to define shared layers which share the same parameters. Shared layers are layer instances that are reused multiple times in the same model. As you can see in implementation, to share a layer in the model we call the same layer instance multiple times in `forward` method."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fzEF7c6umpuS",
        "outputId": "f9f3bc4b-14b8-4794-d757-c23df7c06bf5"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "SharedLayerModel(\n",
              "  (input_layer): Linear(in_features=128, out_features=64, bias=True)\n",
              "  (share_layer): Linear(in_features=64, out_features=64, bias=True)\n",
              "  (output_layer): Linear(in_features=64, out_features=5, bias=True)\n",
              ")"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "class SharedLayerModel(nn.Module):\n",
        "    def __init__(self, in_features, **kwargs):\n",
        "        super(SharedLayerModel, self).__init__(**kwargs)\n",
        "        self.input_layer = nn.Linear(in_features, 64)\n",
        "        self.share_layer = nn.Linear(64, 64)\n",
        "        self.output_layer = nn.Linear(64, 5)\n",
        "\n",
        "    def forward(self, inputs):\n",
        "        x = F.relu(self.input_layer(inputs))\n",
        "        # Now we apply the share layer thrice\n",
        "        for _ in range(3):\n",
        "            x = F.relu(self.share_layer(x))\n",
        "\n",
        "        x = F.softmax(self.output_layer(x), dim=-1)\n",
        "        return x\n",
        "# Define Model\n",
        "model = SharedLayerModel(128)\n",
        "model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GbUNKdtymXlL",
        "outputId": "c35598ed-4e5d-4ad1-9031-8221ed9e2cd1"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[0.2091, 0.2111, 0.2165, 0.1879, 0.1754],\n",
              "        [0.2042, 0.2142, 0.2182, 0.1879, 0.1755],\n",
              "        [0.2057, 0.2142, 0.2177, 0.1875, 0.1749],\n",
              "        [0.2042, 0.2124, 0.2193, 0.1894, 0.1747],\n",
              "        [0.2035, 0.2132, 0.2198, 0.1894, 0.1741]], grad_fn=<SoftmaxBackward0>)"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Forward pass with random inputs=\n",
        "model(torch.randn(5, 128))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u4dttz-Sln3s"
      },
      "source": [
        "##Key Takeaways:\n",
        "\n",
        "\n",
        "1.   Learn to implement keras model in three different ways\n",
        "2.   Sequential model is used for implementing simple stacking layers, Functional api is used for implementing complex models like multiple inputs and outputs, sharable layers and Model subclassing allows us to build our own custom model.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uB-dIFbKNGNE"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
